{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNK0ITS8hXrV"
      },
      "source": [
        "# Demo: Overfitting, Weight-Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcSnaL94hXrV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znGflAN5llnj"
      },
      "source": [
        "$w_\\mathrm{new} = w - \\alpha\\nabla J(w)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfAk_ADcllnk"
      },
      "source": [
        "### Plot polynomial\n",
        "\n",
        "Here we plot the polynomial curve $f(x) = 5x^3 + 4x^2 - 2x - 0.5$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PVihgnqllnl",
        "outputId": "8ebc8abf-740c-41ee-8b7e-0dd699198bf1"
      },
      "outputs": [],
      "source": [
        "nsamp = 25 # number of samples taken\n",
        "p = np.array([5,1,-2,-.5]) # true coefficients\n",
        "var = 0.1 # noise variance\n",
        "\n",
        "# we'll take a set of measurements uniformly\n",
        "x = np.linspace(-1,1,nsamp)\n",
        "y_true = np.polyval(p,x)\n",
        "\n",
        "plt.plot(x,y_true)\n",
        "# we can force a scatter plot in plt.plot by making the third argument 'o'\n",
        "plt.plot(x,y_true,'ob',markeredgecolor='black');\n",
        "plt.grid();\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.xlim([-1,1])\n",
        "plt.ylim([-3,4])\n",
        "plt.legend(['True Process, y_true','Noisy Measurement, y']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7gUi5JN-llnm",
        "outputId": "a64d6bbe-36c5-4011-e39f-a97f151d1775"
      },
      "outputs": [],
      "source": [
        "nsamp = 25 # number of samples taken\n",
        "p = np.array([5,1,-2,-.5]) # true coefficients\n",
        "var = 0.1 # noise variance\n",
        "\n",
        "# we'll take a set of measurements uniformly\n",
        "x = np.linspace(-1,1,nsamp)\n",
        "y_true = np.polyval(p,x)\n",
        "# noisy measurement, ym. use sqrt(var) as numpy normal standard deviation\n",
        "y = y_true + np.random.normal(0, np.sqrt(var), nsamp)\n",
        "\n",
        "plt.plot(x,y_true)\n",
        "# we can force a scatter plot in plt.plot by making the third argument 'o'\n",
        "plt.plot(x,y,'ob',markeredgecolor='black');\n",
        "plt.grid();\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.xlim([-1,1])\n",
        "plt.ylim([-3,4])\n",
        "plt.legend(['True Process, y_true','Noisy Measurement, y']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syyXCKIhhXrb"
      },
      "outputs": [],
      "source": [
        "# train test validation split\n",
        "ntrain = 15\n",
        "nval = 5\n",
        "ntest = 5\n",
        "\n",
        "inds = np.random.permutation(nsamp)\n",
        "\n",
        "train_choices = inds[:ntrain]\n",
        "val_choices = inds[ntrain:ntrain+nval]\n",
        "test_choices = inds[ntrain+nval:]\n",
        "\n",
        "xtrain, ytrain = x[train_choices], y[train_choices]\n",
        "xval, yval     = x[val_choices], y[val_choices]\n",
        "xtest, ytest   = x[test_choices], y[test_choices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-1DKtbllnn"
      },
      "source": [
        "### Design Matrix\n",
        "\n",
        "We have the design matrix as $D = \\begin{bmatrix}\n",
        "1 & x_1 & x_1^2 & x_1^3 & \\cdots & x_1^{M}\\\\\n",
        "1 & x_2 & x_2^2 & x_2^3 & \\cdots & x_2^{M}\\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "1 & x_n & x_n^2 & x_n^3 & \\cdots & x_n^{M}\n",
        "\\end{bmatrix}$\n",
        "\n",
        "- Complete the design matrix and set M = 25, the shape of the design matrix should be (15, 26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTAjbD8nllno",
        "outputId": "7edc6b07-1122-49b8-a17a-22dd32c334d2"
      },
      "outputs": [],
      "source": [
        "ones = np.ones((15, 1))\n",
        "xtrain_reshaped = xtrain.reshape((-1, 1))\n",
        "X = np.hstack((ones, xtrain_reshaped))\n",
        "x_train_reshaped_squared = xtrain_reshaped**2\n",
        "\n",
        "np.hstack((X, x_train_reshaped_squared))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wTKUe2lehXrd",
        "outputId": "d35937d0-b2fc-4b64-b99b-989aebb655cc"
      },
      "outputs": [],
      "source": [
        "# forming the design matrix\n",
        "# features x, model order M\n",
        "\n",
        "def design_matrix(x, M):\n",
        "    # TODO\n",
        "    # To-do\n",
        "\n",
        "    # 1. create the empty array of ones\n",
        "    Design_Matrix = np.ones((x.shape[0],M+1)) # use the np.ones function\n",
        "\n",
        "    # 2. use a for loop to populate the Design_Matrix columnwise\n",
        "    for j in range(M):\n",
        "        Design_Matrix[:,j+1] = x**(j+1)#provide an expression for each column of Design_Matrix\n",
        "\n",
        "\n",
        "    return Design_Matrix\n",
        "\n",
        "\n",
        "M = 10\n",
        "Xtrain = design_matrix(xtrain, M)\n",
        "Xval = design_matrix(xval,M)\n",
        "Xtest = design_matrix(xtest,M)\n",
        "print(Xtrain.shape, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "OaQtjOPHhXrf",
        "outputId": "78dbde94-e417-450a-c72e-802a9b507598"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# TODO\n",
        "# fit the polynomial model using linear regression\n",
        "# 1. Use 'reg' as name for your regressor and set fit_intercept = False\n",
        "reg = linear_model.LinearRegression(fit_intercept=False)\n",
        "reg.fit(Xtrain, ytrain.reshape((-1, 1)))\n",
        "w = reg.coef_\n",
        "\n",
        "\n",
        "# print the training error RMSE\n",
        "# 1. generate the predictions y_train_pred\n",
        "# 2. use the skearn metric MSE to calculate RMSE (note: pass squared=False)\n",
        "yhat = reg.predict(Xtrain)\n",
        "RMSE = np.sqrt(np.mean((ytrain-yhat)**2) )\n",
        "print(\"Train RMSE = %.4f\" % RMSE)\n",
        "\n",
        "\n",
        "# print the test error RMS\n",
        "# 1. generate the predictions y_test_pred\n",
        "# 2. use the skearn metric MSE to calculate RMSE (note: pass squared=False)\n",
        "Xtest = design_matrix(xtest, M)\n",
        "yhat = reg.predict(Xtest)\n",
        "RMSE = np.sqrt( np.mean((ytest-yhat)**2) )\n",
        "print(\"Test RMSE = %.4f\" % RMSE)\n",
        "\n",
        "# see what happens to the error values above as M is set to a high number\n",
        "\n",
        "# plotting\n",
        "x_line = np.linspace(-1,1,500)\n",
        "X_line = design_matrix(x_line, M)\n",
        "y_line = reg.predict(X_line)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_line, y_line)\n",
        "plt.plot(xtrain,ytrain,'o',markeredgecolor='black')\n",
        "plt.plot(xtest,ytest,'o',markeredgecolor='black')\n",
        "# plt.xlim([-1,1])\n",
        "# plt.ylim([-3,4])\n",
        "plt.legend(['Model','Train Points', 'Test Points'])\n",
        "plt.show()\n",
        "\n",
        "w = reg.coef_\n",
        "print(\"w = \")\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "    print(w.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n-YfPkVllnr"
      },
      "source": [
        "### weight based regularization\n",
        "\n",
        "- Lasso: L1 norm regularizer $\\displaystyle\\frac{1}{2n_\\mathrm{samples}}\\|y - Xw\\|^2_2 + \\alpha\\|w\\|_1$\n",
        "\n",
        "\n",
        "- Ridge: L2 norm regularizer $\\displaystyle\\|y - Xw\\|^2_2 + \\alpha\\|w\\|^2_2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "KJAgZ3wshXri",
        "outputId": "86574d27-07b6-436f-b5eb-6bcf6222fd64"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "\n",
        "# Using the following models to fit the data\n",
        "# reg = linear_model.Lasso(alpha=.02, fit_intercept=False)\n",
        "# reg = linear_model.Ridge(alpha=.05, fit_intercept=False)\n",
        "\n",
        "#***********************************************************************************#\n",
        "\n",
        "# print the training error RMSE\n",
        "# 1. generate the predictions y_train_pred\n",
        "# 2. use the skearn metric MSE to calculate RMSE (note: pass squared=False)\n",
        "\n",
        "#***********************************************************************************#\n",
        "\n",
        "# print the validation error RMSE\n",
        "# 1. generate the predictions y_val_pred\n",
        "# 2. use the skearn metric MSE to calculate RMSE (note: pass squared=False)\n",
        "\n",
        "#***********************************************************************************#\n",
        "\n",
        "# print the test error RMSE\n",
        "# 1. generate the predictions y_test_pred\n",
        "# 2. use the skearn metric MSE to calculate RMSE (note: pass squared=False)\n",
        "\n",
        "#***********************************************************************************#\n",
        "\n",
        "\n",
        "# see what happens to the error values above as M is set to a high number\n",
        "# print(f\"The train error is, {mse_train:.3f}\")\n",
        "# print(f\"The validation error is, {mse_val:.3f}\")\n",
        "# print(f\"The test error is, {mse_test:.3f}\")\n",
        "\n",
        "\n",
        "# plotting\n",
        "\n",
        "x_line = np.linspace(-1,1,500)\n",
        "X_line = design_matrix(x_line, M)\n",
        "y_line = reg.predict(X_line)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_line, y_line)\n",
        "plt.plot(xtrain,ytrain,'o',markeredgecolor='black')\n",
        "plt.plot(xtest,ytest,'o',markeredgecolor='black')\n",
        "plt.plot(xval,yval,'o',markeredgecolor='black')\n",
        "# plt.xlim([-1,1])\n",
        "# plt.ylim([-3,3])\n",
        "plt.legend(['Model','Train Points', 'Test Points', 'Val Points'])\n",
        "plt.show()\n",
        "\n",
        "w = reg.coef_\n",
        "print(\"w = \")\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "    print(w.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": true,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
